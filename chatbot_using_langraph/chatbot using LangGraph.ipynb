{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "13547a16-5b51-4f9c-9e7c-abeedca36566",
   "metadata": {},
   "source": [
    "#  chatbot using LangGraph, LangChain, and Ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8be657ce-47d9-4ec7-955f-8407a8ea2f40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langgraph\n",
      "  Using cached langgraph-0.3.21-py3-none-any.whl.metadata (7.7 kB)\n",
      "Collecting langchain-core<0.4,>=0.1 (from langgraph)\n",
      "  Using cached langchain_core-0.3.49-py3-none-any.whl.metadata (5.9 kB)\n",
      "Collecting langgraph-checkpoint<3.0.0,>=2.0.10 (from langgraph)\n",
      "  Using cached langgraph_checkpoint-2.0.23-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting langgraph-prebuilt<0.2,>=0.1.1 (from langgraph)\n",
      "  Using cached langgraph_prebuilt-0.1.7-py3-none-any.whl.metadata (5.0 kB)\n",
      "Collecting langgraph-sdk<0.2.0,>=0.1.42 (from langgraph)\n",
      "  Using cached langgraph_sdk-0.1.60-py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting xxhash<4.0.0,>=3.5.0 (from langgraph)\n",
      "  Downloading xxhash-3.5.0-cp312-cp312-win_amd64.whl.metadata (13 kB)\n",
      "Collecting langsmith<0.4,>=0.1.125 (from langchain-core<0.4,>=0.1->langgraph)\n",
      "  Using cached langsmith-0.3.19-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting tenacity!=8.4.0,<10.0.0,>=8.1.0 (from langchain-core<0.4,>=0.1->langgraph)\n",
      "  Using cached tenacity-9.0.0-py3-none-any.whl.metadata (1.2 kB)\n",
      "Collecting jsonpatch<2.0,>=1.33 (from langchain-core<0.4,>=0.1->langgraph)\n",
      "  Using cached jsonpatch-1.33-py2.py3-none-any.whl.metadata (3.0 kB)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\konde\\anaconda3\\envs\\env_genai\\lib\\site-packages (from langchain-core<0.4,>=0.1->langgraph) (6.0.2)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in c:\\users\\konde\\anaconda3\\envs\\env_genai\\lib\\site-packages (from langchain-core<0.4,>=0.1->langgraph) (24.2)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in c:\\users\\konde\\anaconda3\\envs\\env_genai\\lib\\site-packages (from langchain-core<0.4,>=0.1->langgraph) (4.13.0)\n",
      "Collecting pydantic<3.0.0,>=2.7.4 (from langchain-core<0.4,>=0.1->langgraph)\n",
      "  Using cached pydantic-2.11.0-py3-none-any.whl.metadata (63 kB)\n",
      "Collecting ormsgpack<2.0.0,>=1.8.0 (from langgraph-checkpoint<3.0.0,>=2.0.10->langgraph)\n",
      "  Downloading ormsgpack-1.9.1-cp312-cp312-win_amd64.whl.metadata (44 kB)\n",
      "Requirement already satisfied: httpx>=0.25.2 in c:\\users\\konde\\anaconda3\\envs\\env_genai\\lib\\site-packages (from langgraph-sdk<0.2.0,>=0.1.42->langgraph) (0.28.1)\n",
      "Collecting orjson>=3.10.1 (from langgraph-sdk<0.2.0,>=0.1.42->langgraph)\n",
      "  Downloading orjson-3.10.16-cp312-cp312-win_amd64.whl.metadata (42 kB)\n",
      "Requirement already satisfied: anyio in c:\\users\\konde\\anaconda3\\envs\\env_genai\\lib\\site-packages (from httpx>=0.25.2->langgraph-sdk<0.2.0,>=0.1.42->langgraph) (4.9.0)\n",
      "Requirement already satisfied: certifi in c:\\users\\konde\\anaconda3\\envs\\env_genai\\lib\\site-packages (from httpx>=0.25.2->langgraph-sdk<0.2.0,>=0.1.42->langgraph) (2025.1.31)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\konde\\anaconda3\\envs\\env_genai\\lib\\site-packages (from httpx>=0.25.2->langgraph-sdk<0.2.0,>=0.1.42->langgraph) (1.0.7)\n",
      "Requirement already satisfied: idna in c:\\users\\konde\\anaconda3\\envs\\env_genai\\lib\\site-packages (from httpx>=0.25.2->langgraph-sdk<0.2.0,>=0.1.42->langgraph) (3.10)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\konde\\anaconda3\\envs\\env_genai\\lib\\site-packages (from httpcore==1.*->httpx>=0.25.2->langgraph-sdk<0.2.0,>=0.1.42->langgraph) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\konde\\anaconda3\\envs\\env_genai\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4,>=0.1->langgraph) (3.0.0)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\users\\konde\\anaconda3\\envs\\env_genai\\lib\\site-packages (from langsmith<0.4,>=0.1.125->langchain-core<0.4,>=0.1->langgraph) (2.32.3)\n",
      "Collecting requests-toolbelt<2.0.0,>=1.0.0 (from langsmith<0.4,>=0.1.125->langchain-core<0.4,>=0.1->langgraph)\n",
      "  Using cached requests_toolbelt-1.0.0-py2.py3-none-any.whl.metadata (14 kB)\n",
      "Collecting zstandard<0.24.0,>=0.23.0 (from langsmith<0.4,>=0.1.125->langchain-core<0.4,>=0.1->langgraph)\n",
      "  Downloading zstandard-0.23.0-cp312-cp312-win_amd64.whl.metadata (3.0 kB)\n",
      "Collecting annotated-types>=0.6.0 (from pydantic<3.0.0,>=2.7.4->langchain-core<0.4,>=0.1->langgraph)\n",
      "  Using cached annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting pydantic-core==2.33.0 (from pydantic<3.0.0,>=2.7.4->langchain-core<0.4,>=0.1->langgraph)\n",
      "  Downloading pydantic_core-2.33.0-cp312-cp312-win_amd64.whl.metadata (6.9 kB)\n",
      "Collecting typing-inspection>=0.4.0 (from pydantic<3.0.0,>=2.7.4->langchain-core<0.4,>=0.1->langgraph)\n",
      "  Using cached typing_inspection-0.4.0-py3-none-any.whl.metadata (2.6 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\konde\\anaconda3\\envs\\env_genai\\lib\\site-packages (from requests<3,>=2->langsmith<0.4,>=0.1.125->langchain-core<0.4,>=0.1->langgraph) (3.4.1)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\konde\\anaconda3\\envs\\env_genai\\lib\\site-packages (from requests<3,>=2->langsmith<0.4,>=0.1.125->langchain-core<0.4,>=0.1->langgraph) (2.3.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\users\\konde\\anaconda3\\envs\\env_genai\\lib\\site-packages (from anyio->httpx>=0.25.2->langgraph-sdk<0.2.0,>=0.1.42->langgraph) (1.3.1)\n",
      "Using cached langgraph-0.3.21-py3-none-any.whl (138 kB)\n",
      "Using cached langchain_core-0.3.49-py3-none-any.whl (420 kB)\n",
      "Using cached langgraph_checkpoint-2.0.23-py3-none-any.whl (41 kB)\n",
      "Using cached langgraph_prebuilt-0.1.7-py3-none-any.whl (25 kB)\n",
      "Using cached langgraph_sdk-0.1.60-py3-none-any.whl (47 kB)\n",
      "Downloading xxhash-3.5.0-cp312-cp312-win_amd64.whl (30 kB)\n",
      "Using cached jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
      "Using cached langsmith-0.3.19-py3-none-any.whl (351 kB)\n",
      "Downloading orjson-3.10.16-cp312-cp312-win_amd64.whl (133 kB)\n",
      "Downloading ormsgpack-1.9.1-cp312-cp312-win_amd64.whl (125 kB)\n",
      "Using cached pydantic-2.11.0-py3-none-any.whl (442 kB)\n",
      "Downloading pydantic_core-2.33.0-cp312-cp312-win_amd64.whl (2.0 MB)\n",
      "   ---------------------------------------- 0.0/2.0 MB ? eta -:--:--\n",
      "   ---------------- ----------------------- 0.8/2.0 MB 3.7 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 1.6/2.0 MB 3.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.0/2.0 MB 3.6 MB/s eta 0:00:00\n",
      "Using cached tenacity-9.0.0-py3-none-any.whl (28 kB)\n",
      "Using cached annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "Using cached requests_toolbelt-1.0.0-py2.py3-none-any.whl (54 kB)\n",
      "Using cached typing_inspection-0.4.0-py3-none-any.whl (14 kB)\n",
      "Downloading zstandard-0.23.0-cp312-cp312-win_amd64.whl (495 kB)\n",
      "Installing collected packages: zstandard, xxhash, typing-inspection, tenacity, pydantic-core, ormsgpack, orjson, jsonpatch, annotated-types, requests-toolbelt, pydantic, langsmith, langgraph-sdk, langchain-core, langgraph-checkpoint, langgraph-prebuilt, langgraph\n",
      "Successfully installed annotated-types-0.7.0 jsonpatch-1.33 langchain-core-0.3.49 langgraph-0.3.21 langgraph-checkpoint-2.0.23 langgraph-prebuilt-0.1.7 langgraph-sdk-0.1.60 langsmith-0.3.19 orjson-3.10.16 ormsgpack-1.9.1 pydantic-2.11.0 pydantic-core-2.33.0 requests-toolbelt-1.0.0 tenacity-9.0.0 typing-inspection-0.4.0 xxhash-3.5.0 zstandard-0.23.0\n"
     ]
    }
   ],
   "source": [
    "!pip install langgraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bcb00fc4-8684-477e-b5aa-afb6f937c4b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\konde\\AppData\\Local\\Temp\\ipykernel_7740\\2576623463.py:18: LangChainDeprecationWarning: The class `Ollama` was deprecated in LangChain 0.3.1 and will be removed in 1.0.0. An updated version of the class exists in the :class:`~langchain-ollama package and should be used instead. To use it run `pip install -U :class:`~langchain-ollama` and import as `from :class:`~langchain_ollama import OllamaLLM``.\n",
      "  llm = Ollama(model=\"llama3.2\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chatbot started! Type 'quit', 'exit', or 'q' to stop.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "User:  hi\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assistant: Hello! How can I assist you today?\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "User:  what is astro physics.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assistant: Astrophysics is the branch of astronomy that deals with the physical nature of celestial objects and phenomena. It's a field that seeks to understand the behavior, properties, and evolution of stars, galaxies, black holes, and other objects in the universe.\n",
      "\n",
      "Astrophysicists use a combination of mathematical models, computational simulations, and observational data from telescopes and spacecraft to study the physical processes that govern the universe. This can include topics such as:\n",
      "\n",
      "1. Stellar physics: The study of the properties and behavior of stars, including their structure, evolution, and interactions.\n",
      "2. Galactic dynamics: The study of the behavior of galaxies, including their rotation curves, star clusters, and galaxy collisions.\n",
      "3. Cosmology: The study of the origin, evolution, and fate of the universe as a whole.\n",
      "4. Planetary science: The study of planets, moons, asteroids, comets, and other objects in our solar system.\n",
      "5. High-energy astrophysics: The study of high-energy phenomena such as supernovae, gamma-ray bursts, and black hole mergers.\n",
      "\n",
      "Astrophysicists often work at the intersection of multiple disciplines, including physics, mathematics, computer science, and engineering. They use a range of tools and techniques to analyze data, simulate phenomena, and make predictions about future events in the universe.\n",
      "\n",
      "Some examples of what astro-physicists might do include:\n",
      "\n",
      "* Designing and operating space telescopes or satellites to study distant objects\n",
      "* Analyzing data from spacecraft missions to other planets or asteroids\n",
      "* Conducting computer simulations of astrophysical phenomena, such as supernovae or black hole mergers\n",
      "* Developing new theoretical models to explain observed phenomena in the universe\n",
      "\n",
      "Overall, astro-physics is a vibrant and rapidly evolving field that seeks to understand the fundamental laws of the universe and our place within it.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "User:  what is astral projection\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assistant: Astral projection, also known as out-of-body experience (OBE), is a phenomenon where an individual's consciousness or spirit temporarily leaves their physical body, allowing them to perceive the world from a non-physical perspective. During an OBE, the person may feel themselves floating above their body, observing their surroundings, and potentially interacting with other beings or energies.\n",
      "\n",
      "The concept of astral projection has been explored in various cultures and spiritual traditions for centuries. Some believe that it's a natural ability that can be developed through meditation, visualization, and other practices. Others see it as a paranormal phenomenon that requires special skills or abilities.\n",
      "\n",
      "During an OBE, individuals may report experiencing a range of sensations, including:\n",
      "\n",
      "1. Feeling detached from their physical body\n",
      "2. Seeing themselves and their surroundings from above\n",
      "3. Observing events in slow motion or from multiple perspectives\n",
      "4. Experiencing emotions and sensations that are not associated with their physical body\n",
      "5. Perceiving energy fields or auras around people or objects\n",
      "\n",
      "Astral projection is often described as a way to:\n",
      "\n",
      "1. Explore the spiritual realm and connect with other beings\n",
      "2. Gain insight into personal issues, life purpose, or future events\n",
      "3. Develop psychic abilities and intuition\n",
      "4. Overcome fears, anxieties, or phobias\n",
      "5. Achieve higher states of consciousness and self-awareness\n",
      "\n",
      "While some people claim that astral projection is a valuable tool for personal growth and spiritual development, others remain skeptical about its validity as a paranormal phenomenon.\n",
      "\n",
      "There are different types of OBEs, including:\n",
      "\n",
      "1. Simple OBE: A brief, temporary experience where the individual feels detached from their body\n",
      "2. Complex OBE: A more extensive experience that can last for hours or even days\n",
      "3. Lucid dreaming: An OBE that occurs during sleep and is often accompanied by vivid dreams\n",
      "\n",
      "If you're interested in exploring astral projection, there are various techniques and practices that can help you develop this skill, such as:\n",
      "\n",
      "1. Meditation and visualization\n",
      "2. Breathwork and relaxation techniques\n",
      "3. Sensory deprivation or isolation tank experiences\n",
      "4. Dreaming and journaling exercises\n",
      "5. Working with a spiritual guide or mentor\n",
      "\n",
      "Keep in mind that astral projection is not scientifically proven, and its validity depends on individual perspectives and experiences.\n",
      "\n",
      "Would you like to explore more about astral projection or discuss other related topics?\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "User:  q\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Goodbye!\n"
     ]
    }
   ],
   "source": [
    "from typing import List, Dict\n",
    "from dataclasses import dataclass, field\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "# from langchain_ollama.llms import OllamaLLM\n",
    "from langchain_community.llms import Ollama\n",
    "\n",
    "\n",
    "# Step 1: Define State using a dataclass\n",
    "@dataclass\n",
    "class State:\n",
    "    messages: List[Dict[str, str]] = field(default_factory=list)\n",
    "\n",
    "\n",
    "# Step 2: Initialize StateGraph\n",
    "graph_builder = StateGraph(State)\n",
    "\n",
    "# Initialize the LLM (using Llama 3.2)\n",
    "llm = Ollama(model=\"llama3.2\")\n",
    "\n",
    "\n",
    "# Define chatbot function\n",
    "def chatbot(state: State) -> Dict[str, List[Dict[str, str]]]:\n",
    "    try:\n",
    "        response = llm.invoke(state.messages)\n",
    "        state.messages.append({\"role\": \"assistant\", \"content\": response})  # Treat response as a string\n",
    "        return {\"messages\": state.messages}\n",
    "    except Exception as e:\n",
    "        return {\"messages\": [{\"role\": \"assistant\", \"content\": f\"Error: {str(e)}\"}]}\n",
    "\n",
    "\n",
    "# Add nodes and edges\n",
    "graph_builder.add_node(\"chatbot\", chatbot)\n",
    "graph_builder.add_edge(START, \"chatbot\")\n",
    "graph_builder.add_edge(\"chatbot\", END)\n",
    "\n",
    "# Compile the graph\n",
    "graph = graph_builder.compile()\n",
    "\n",
    "\n",
    "# Stream updates\n",
    "def stream_graph_updates(user_input: str):    \n",
    "    state = State(messages=[{\"role\": \"user\", \"content\": user_input}])\n",
    "    \n",
    "    try:\n",
    "        for event in graph.stream(state):\n",
    "            for value in event.values():\n",
    "                print(\"Assistant:\", value[\"messages\"][-1][\"content\"])\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "\n",
    "\n",
    "# Run chatbot in a loop\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"Chatbot started! Type 'quit', 'exit', or 'q' to stop.\")\n",
    "\n",
    "    while True:\n",
    "        try:\n",
    "            user_input = input(\"User: \").strip()\n",
    "            if user_input.lower() in [\"quit\", \"exit\", \"q\"]:\n",
    "                print(\"Goodbye!\")\n",
    "                break\n",
    "\n",
    "            stream_graph_updates(user_input)\n",
    "\n",
    "        except KeyboardInterrupt:\n",
    "            print(\"\\nGoodbye!\")\n",
    "            break\n",
    "        except Exception as e:\n",
    "            print(f\"An error occurred: {e}\")\n",
    "            break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f72c0a2a-f855-4477-82c1-51a005768086",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a638c92-58be-4614-a5b9-f2e0fe33ed51",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75f132fd-ca6f-4cf3-a51e-c419e62abab5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
